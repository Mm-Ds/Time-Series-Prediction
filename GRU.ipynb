{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRU.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1zMaWPbjLxmfhaMacGNGkdGNoLGXJfKAG","authorship_tag":"ABX9TyOyngi7dsw/WQ2UvY0ejaxI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jj26mh2ugK6z","colab_type":"text"},"source":["Le code suivant est basé, quasiment dans son intégralité ( des modifications ont été apportées au besoin) , sur les codes disponbles via ces liens:\n","https://machinelearningmastery.com/how-to-grid-search-deep-learning-models-for-time-series-forecasting/\n","https://machinelearningmastery.com/time-series-prediction-with-deep-learning-in-python-with-keras/"]},{"cell_type":"code","metadata":{"id":"y6GUMsaT5MIU","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import math\n","from operator import itemgetter\n","import time\n","from math import sqrt\n","from numpy import *\n","from sklearn.preprocessing import MinMaxScaler\n","from numpy import mean\n","from pandas import DataFrame,concat,read_csv, Series\n","from sklearn.metrics import mean_squared_error\n","from keras.models import Sequential,model_from_json\n","from keras.layers import Dense,GRU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tN3mluA68ozl","colab_type":"code","colab":{}},"source":["# split a univariate dataset into train/test sets\n","def train_test_split(data, train_size):\n","  train = dataset[0:train_size, ]\n","  test = dataset[train_size:len(dataset), ]\n","  return train, test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bJWxncT9n2R","colab_type":"code","colab":{}},"source":["# transform list into supervised learning format\n","def series_to_supervised(data, n_in=1, n_out=1):\n","\tdf = DataFrame(data)\n","\tcols = list()\n","\t# input sequence (t-n, ... t-1)\n","\tfor i in range(n_in, 0, -1):\n","\t\tcols.append(df.shift(i))\n","\t# forecast sequence (t, t+1, ... t+n)\n","\tfor i in range(0, n_out):\n","\t\tcols.append(df.shift(-i))\n","\t# put it all together\n","\tagg = concat(cols, axis=1)\n","\t# drop rows with NaN values\n","\tagg.dropna(inplace=True)\n","\treturn agg.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WX0_DHUp-Eqj","colab_type":"text"},"source":["# Construction et entrainement du modèle"]},{"cell_type":"code","metadata":{"id":"0u9vOcvF54o8","colab_type":"code","colab":{}},"source":["def model_fit(train, config):\n","  # unpack config\n","  n_input, n_nodes, n_epochs, n_batch, n_layers= config\t\n","  # transform series into supervised format\n","  data = series_to_supervised(train, n_in=n_input)\n","  # separate inputs and outputs\n","  train_x, train_y = data[:, :-1], data[:, -1]                #x: la séquence (de taille n_in(le nombre de \"timsteps\" passées à utiliser pour la prédiction)) , y: le \"timestep\" cible\n","  \n","  # reshape input data into [samples, timesteps, features]\n","  n_features = 1\n","  train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n","  # define model\n","  model = Sequential()\n","  for i in range(n_layers):\n","    model.add(GRU(n_nodes, activation='relu', input_shape=(n_input, n_features)))\n","  model.add(Dense(1))\n","  model.compile(loss='mean_squared_error', optimizer='adam')\n","  # fit model\n","  start = time.time()\n","  model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=7)\n","  print(\"Temps d'entrainement =   %s s\" % (time.time() - start))\n","  return model\n","\n","# model.add(SimpleRNN(units=4, input_shape=(trainX.shape[1], trainX.shape[2])))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b_pFOu2R-14A","colab_type":"text"},"source":["# Calcul RMSE"]},{"cell_type":"code","metadata":{"id":"M8ethXrM5ZRs","colab_type":"code","colab":{}},"source":["# root mean squared error or rmse\n","def measure_rmse(actual, predicted):\n","\treturn sqrt(mean_squared_error(actual, predicted))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HivzdRRaCSxi","colab_type":"text"},"source":["# Prédiction"]},{"cell_type":"code","metadata":{"id":"avDnTMu7CRpU","colab_type":"code","colab":{}},"source":["# forecast with the fit model\n","def model_predict(model, history, config):\n","\t# unpack config\n","\tn_input, _, _, _,_ = config\n","\t# reshape sample into [samples, timesteps, features]\n","\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n","\t# forecast\n","\tyhat = model.predict(x_input, verbose=0)\n","\treturn yhat[0]\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FgVUG8b-xYx","colab_type":"text"},"source":["# Validation Walk Forward"]},{"cell_type":"code","metadata":{"id":"7v_HWdqH7y_R","colab_type":"code","colab":{}},"source":["# walk-forward validation for univariate data\n","def walk_forward_validation(data, train_size, cfg):\n","  predictions = list()\n","  # split dataset\n","  train, test = train_test_split(data,train_size)\n","  # fit model\n","  model = model_fit(train, cfg)\n","  # seed history with training dataset\n","  history = [x for x in train]\n","  # step over each time-step in the test set\n","  for i in range(len(test)):\n","    # fit model and make forecast for history\n","    yhat = model_predict(model, history, cfg)\n","    # store forecast in list of predictions\n","    predictions.append(yhat)\n","    # add actual observation to history for the next loop\n","    history.append(test[i])\n","  #invert predictions and test \n","  predictions = scaler.inverse_transform(predictions)\n","  test = scaler.inverse_transform(test)\n","  # estimate prediction error\n","  error = measure_rmse(test, predictions)\n","  print('> %s RMSE %.3f' %(str(cfg) , error))\n","  return error,model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJKB_OaB8eay","colab_type":"code","colab":{}},"source":["# score a model, return None on failure\n","def repeat_evaluate(data, config, train_size, n_repeats=3):\n","  # convert config to a key\t\n","  # fit and evaluate the model n times\n","  scores = [walk_forward_validation(data, train_size, config) for _ in range(n_repeats)]\n","  # summarize score\n","  \n","  result = mean([t[0] for t in scores])\n","  print('> Model[%s] %.3f' % (str(config), result))\n","  return (config, result, scores[-1][1])    # la configuration courante, la moyenne des erreures et le dernier modèle évalué"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1cVEFSvQ-et9","colab_type":"text"},"source":["# Grille de recherche \n"]},{"cell_type":"code","metadata":{"id":"JWueqPa68AMS","colab_type":"code","colab":{}},"source":["# grid search configs\n","def grid_search(data, cfg_list, train_size):\n","\t# evaluate configs\n","\tscores = [repeat_evaluate(data, cfg, train_size) for cfg in cfg_list]\n","\t# sort configs by error, asc\n","\tscores.sort(key=itemgetter(1))\n","\treturn scores                              # retourne une liste de tuples où chaque tuple est de la forme (config,resultat,dernier modèle évalué dans model_evaluate())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fei3jw0u-mgE","colab_type":"text"},"source":["# Définition des configurations de test"]},{"cell_type":"code","metadata":{"id":"EaG5iKnW8ChO","colab_type":"code","colab":{}},"source":["# create a list of configs to try\n","def model_configs():\n","\t# define scope of configs\n","\tn_input = [3,7,30]\n","\tn_nodes = [4,50,100]\n","\tn_epochs = [200]\n","\tn_batch = [1, 150]\n","\tn_layers=[1, ]\n","\t# create configs\n","\tconfigs = list()\n","\tfor i in n_input:\n","\t\tfor j in n_nodes:\n","\t\t\tfor k in n_epochs:\n","\t\t\t\tfor l in n_batch:\n","\t\t\t\t\tfor m in n_layers:\n","\t\t\t\t\t\tcfg = [i, j, k, l,m]\n","\t\t\t\t\t\tconfigs.append(cfg)\n","\tprint('Total configs: %d' % len(configs))\n","\treturn configs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gC5YFtEMmYMg","colab_type":"text"},"source":["# Exécution de la grille de recherche"]},{"cell_type":"code","metadata":{"id":"rjCe5eBZ3N2h","colab_type":"code","colab":{}},"source":["random.seed(7)\n","data = read_csv('/content/drive/My Drive/TER/pass.csv', delimiter=';', usecols=[1], skiprows=0, encoding=\"utf-8\")\n","# print(data)\n","plt.plot(data)\n","plt.show()\n","dataset = data.values\n","dataset = data.astype('float32')\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","# plt.plot(dataset)\n","# plt.show()\n","\n","train_size = int(len(dataset) * 0.67)\n","cfg_list = model_configs()\n","# grid search\n","scores = grid_search(data, cfg_list, train_size)\n","print('done')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GP7XUnUomVUS","colab_type":"text"},"source":["# Résumé des résultats"]},{"cell_type":"code","metadata":{"id":"gTABAFALnIZn","colab_type":"code","colab":{}},"source":["# list top 10 configs\n","\n","print(\"format des configurations: configuration [n_input,n_nodes,n_epochs,n_batch]\")\n","for t in scores:\n","  cfg,score, model = t\n","  print(\"config %s  RMSE %.3f\" %(str(cfg),score))\n","\n","bestconfig,_,bestmodel=scores[1]\n","\n","# serialize model to JSON\n","model_json = model.to_json()\n","path='/content/drive/My Drive/TER/'\n","modelname='SimpleRNN'+str(bestconfig)      # si n_input =1 without window\n","with open(path+modelname+'.json', \"w\") as json_file:\n","  json_file.write(model_json)\n","  # serialize weights to HDF5\n","  model.save_weights(path+modelname+'.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQAPIyAJCrzh","colab_type":"text"},"source":["# (Sinon charger le modèle sauvegardé)"]},{"cell_type":"code","metadata":{"id":"pDjJqWVuMuRH","colab_type":"code","colab":{}},"source":["# load json and create model\n","\n","json_file = open('/content/drive/My Drive/TER/simpleRNN[30, 100, 50, 150].json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"/content/drive/My Drive/TER/simpleRNN[30, 100, 50, 150].h5\")\n","print(\"Loaded model from disk\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FAhkTCkaCj3L","colab_type":"text"},"source":["## RMSE sur les données test "]},{"cell_type":"code","metadata":{"id":"8HktNz1wBSun","colab_type":"code","colab":{}},"source":["# bestconfig=[30, 100, 50, 150]\n","# bestmodel=loaded_model\n","\n","n_input, n_nodes, n_epochs, n_batch= bestconfig\t          \n","n_features = 1\n","# les données dans le format défini plus haut \n","#1- séparation train et test\n","train, test = train_test_split(dataset,train_size)\n","#2- format apprentissage supérvisé\n","trainS = series_to_supervised(train, n_in=n_input)\n","testS = series_to_supervised(test, n_in=n_input)\n","train_x, train_y = trainS[:, :-1], trainS[:, -1] \n","test_x, test_y = testS[:, :-1], testS[:, -1] \n","#3- format [samples,timesteps,features]\n","train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n","test_x = test_x.reshape((test_x.shape[0], test_x.shape[1], n_features))\n","\n","#Prediction\n","y_train_pred=yhat = bestmodel.predict(train_x, verbose=0)\n","y_test_pred=bestmodel.predict(test_x, verbose=0)\n","\n","# inversion de la transformation MinMaxScaler\n","y_train_pred_orig = scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n","y_test_pred_orig = scaler.inverse_transform(y_test_pred.reshape(-1, 1))\n","y_train_orig = scaler.inverse_transform(train_y.reshape(-1, 1))\n","y_test_orig = scaler.inverse_transform(test_y.reshape(-1, 1))\n","\n","testScore = measure_rmse(y_test_orig, y_test_pred_orig)\n","print('RMSE Ensemble test: %.3f  ' % (testScore))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i1k-TJ_DaS03","colab_type":"text"},"source":["# Visualisation des prédictions/données réelles"]},{"cell_type":"code","metadata":{"id":"aTpCazRMaaPf","colab_type":"code","colab":{}},"source":["# Visulaisation\n","\n","trainPredictPlot = empty_like(dataset)\n","trainPredictPlot[:, :] = nan\n","trainPredictPlot[n_input:len(y_train_pred) + n_input, :] = y_train_pred_orig\n","\n","# shift test predictions for plotting\n","testPredictPlot = empty_like(dataset)\n","testPredictPlot[:, :] = nan\n","testPredictPlot[len(y_train_pred) + (n_input * 2):len(dataset), :] = y_test_pred_orig\n","\n","# plot baseline and predictions\n","plt.figure(num=None, figsize=(10, 7), dpi=80, facecolor='w')\n","plt.plot(scaler.inverse_transform(dataset), label='Original Data', color='c')\n","plt.plot(trainPredictPlot, label='y_train_pred', color='m')\n","plt.plot(testPredictPlot, label='y_test_pred', color='b')\n","plt.legend()\n","plt.xlabel('Timesteps')\n","plt.ylabel('Nb de Passages')\n","plt.show()"],"execution_count":0,"outputs":[]}]}